[instance_hyperparameter]
data_type=fp16

tensor_para_size=1
pipeline_para_size=1

enable_custom_all_reduce=0

max_batch_size = 1
max_seq_len = 64

model_name=bert_base
model_dir=/torch6.0_rocm6.0_yanxishi/LI/examples/pytorch/bert/1-gpu/

[bert_base]
model_name = google-bert/bert-base-uncased
vocab_size = 30522
type_vocab_size = 2
max_position_embeddings = 512
position_embedding_type = absolute
hidden_units = 768
num_layers = 2
num_heads = 12
size_per_head = 64
activation_type = gelu
inter_size = 3072
layer_norm_eps = 1e-12
weight_data_type = fp16
tensor_para_size = 1

[request]
request_batch_size=1    ; determine by the request
request_seq_len=64   ; determine by the request

